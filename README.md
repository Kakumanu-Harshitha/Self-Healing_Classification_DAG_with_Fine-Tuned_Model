Self-Healing Classification DAG using LangGraph and LLMs
Overview
This project implements a Self-Healing Classification DAG (Directed Acyclic Graph) using LangGraph and Large Language Models (LLMs). The system simulates an intelligent workflow that can detect, correct, and reclassify failed tasks automatically â€” making it â€œself-healing.â€

It uses a multi-agent LangGraph workflow, where each node (agent) performs specific actions such as data validation, classification, logging, and error recovery.

ðŸš€ Features
âœ… Modular LangGraph-based architecture

âœ… Self-healing mechanism for error recovery

âœ… GPU-accelerated fine-tuning using PyTorch and Transformers

âœ… Parameter-efficient fine-tuning (PEFT) supported

âœ… Real-time progress logging using tqdm and rich

âœ… High compatibility with CUDA-enabled devices

ðŸ§© Project Structure
Self_Healing_Classification_DAG/ â”‚

â”œâ”€â”€ data/ # Input and training datasets

â”œâ”€â”€ models/ # Fine-tuned / saved model weights

â”‚â”€â”€ agents # Agent node implementations

â”‚â”€â”€ dag_builder.py # DAG construction logic

â”‚â”€â”€ trainer.py # Model fine-tuning script

â”‚â”€â”€ evaluator.py # Evaluation and metrics

â”‚â”€â”€ utils # Helper functions

â”‚â”€â”€ init.py

â”œâ”€â”€ requirements.txt # Dependencies

â”œâ”€â”€ README.md # Project documentation

â””â”€â”€ main.py # Entry point to run the workflow

âš™ï¸ Installation Guide
ðŸ§¾ 1. Prerequisites

Python 3.10.x

VS Code (recommended)

CUDA-enabled GPU (NVIDIA)

pip (latest version)

ðŸ§  2. Clone the Repository
git clone https://github.com/Kakumanu-Harshitha/Self_Healing_Classification_DAG.git
cd Self_Healing_Classification_DAG
ðŸ§° 3. Create a Virtual Environment
python -m venv self-healing
self-healing\Scripts\activate     # (Windows)
ðŸ”„ 4. Verify GPU Setup
Before installing libraries, make sure CUDA is available:

nvidia-smi
If this shows your GPU details â†’ proceed. Else, install proper NVIDIA drivers + CUDA Toolkit 11.8.

ðŸ“¦ 5. Install Dependencies
Install all dependencies in one go:

pip install -r requirements.txt
If you face issues with PyTorch installation, run this manually first: ''' bash

pip install torch==2.2.2+cu118 torchvision==0.17.2+cu118 torchaudio==2.2.2+cu118 --index-url https://download.pytorch.org/whl/cu118

##Then install other dependencies:

pip install -r requirements.txt --no-deps


# ðŸ“‹ requirements.txt
```bash 
# GPU & Core Libraries
torch==2.2.2+cu118
torchvision==0.17.2+cu118
torchaudio==2.2.2+cu118
--index-url https://download.pytorch.org/whl/cu118

# Transformers & ML Stack
transformers==4.45.2
datasets==2.19.2
scikit-learn==1.4.2
accelerate==0.31.0
peft==0.11.1
bitsandbytes==0.43.3

# Utilities & Logging
python-json-logger==2.0.7
rich==13.7.1
tqdm==4.66.4
```
ðŸ” 6. Verify Installation
After installing, check if Torch detects the GPU:

import torch
print("CUDA available:", torch.cuda.is_available())
print("GPU Name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU")
ðŸ§ª 7. Run the Project

Start the system:

python main.py
Expected Output:
âœ… DAG Initialized âœ… Agent_1 started classification... âš ï¸ Error detected -> Self-healing triggered âœ… Error resolved. Reclassification successful. ðŸŽ‰ All tasks completed successfully!

ðŸ§¬ Fine-Tuning Script
The fine-tuning script trains your LLM or Transformer model (like bert-base-uncased or roberta-base) on your dataset using parameter-efficient fine-tuning (PEFT).

Example:

python src/trainer.py
--model_name bert-base-uncased
--train_file data/train.csv
--val_file data/val.csv
--output_dir models/self_healing_bert
--epochs 3
--batch_size 8

ðŸ§  How It Works
DAG Initialization â€” LangGraph builds a graph with agent nodes.

Agent Execution â€” Each agent performs classification tasks.

Failure Detection â€” If an error occurs, it triggers a healing agent.

Self-Healing â€” The healing node re-evaluates and fixes misclassifications.

Result Aggregation â€” A judge node validates and finalizes the outcome.

ðŸ“ˆ Future Enhancements
Integrate with LangChain ReAct Agents

Add LLM-based debate judge

Include visual DAG monitor

Implement real-time dashboard with Streamlit
