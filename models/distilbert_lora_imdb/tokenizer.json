{
  "version": "1.0",
  "truncation": {},
  "padding": {},
  "added_tokens": [],
  "normalizer": null,
  "pre_tokenizer": null,
  "post_processor": null,
  "decoder": null,
  "model": {
    "type": "wordpiece",
    "unk_token": "[UNK]"
  }
}
